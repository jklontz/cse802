\documentclass[12pt]{article}
 
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{tikz}
\usetikzlibrary{arrows,shapes,trees} % loads some tikz extensions
 
\begin{document}
 
\title{CSE 802 - Final Project Proposal}
\author{Sunpreet Arora \& Josh Klontz\\
}
 
\maketitle

\section{Objective}
The primary objective of this project is to build an effective classifier for a twenty class subset of the ImageNet \cite{imagenet} database. The proposed classifier will seek to leverage a variety of modern pattern recognition techniques in order to maximize rank 5 accuracy.

\section{Background}
Automated image classification is one of the classical problems in the domain of computer vision and pattern recognition. Although several algorithms exist for categorizing images based on their distinct characteristics or features, large scale image classification is still considered a significantly challenging task. This is primarily because it becomes difficult to find a sufficiently distinctive set of features to distinguish between large number of image classes. Besides, the computational complexity of the classification task scales up considerably as well.\\
The most common approach to image classification is based on the popular information retrieval model known as the bag-of-words (BOW) model. A \textit{visual vocabulary} is first created based on features computed from the training images. The frequency of occurrence of these features (also referred to as \textit{visual words}) in the visual vocabulary is then used for classifying images from the test set.\\
Several databases have been collected for advancing the state-of-the-art in image classification including Caltech 101 \cite{caltech101}, and PASCAL VOC \cite{pascal09}. ImageNet \cite{imagenet} is one of the most recent large scale image databases with 10,000 image classes, and over a million images. Convolutional neural networks (CNNs) have been reported to give the best rank-5 accuracy of around 85\% on the ImageNet database \cite{alex2012}. However, they were implemented on massive parallel GPU's. Another effective approach with a reported top-5 accuracy of 74\% involves Fisher vectors \cite{csurka2011fisher}.


\section{Methodology}
For a generic large scale image classification system, it is quite vital to find features which can efficiently distinguish between a large number of classes. In our view, such features should capture information at three different levels:

\begin{itemize}
\item \textit{Pixel level}: Features based on the pixel intensity values such as color can easily distinguish between several easy image categories such as apples and bananas.

\item \textit{Neighborhood or Local level}: These features encompass information in a small local area around a point of interest, and therefore account for the local variations present in an image. Several image descriptors proposed in recent years such as SIFT \cite{lowe04} and LBP \cite{ahonen06} belong to this class of features.

\item \textit{Global level}: Besides capturing the information at a local level, it is also necessary to measure some global image properties. This is particularly useful to distinguish classes which have similar local variations, but where the global context is significantly different, such as water from sky. One such popular global descriptor to have come up in recent years is 
GIST \cite{oliva2001modeling}.
\end{itemize}

Driven by this idea as well as our analysis of the existing approaches, the brief overall plan is summarized as follows: 

\begin{enumerate}

\item We plan on experimenting with a variety of low-level feature representations including color \cite{sande10}, shape \cite{ahonen06}, and gradient information \cite{lowe04,dalal05}. These features will be pooled into local histograms to form our base descriptor.

\item For this generic image classification task we are leaning in favor of skipping objected detection and localization all together and simply compute descriptors in a dense grid across the image at various scales.

\item  We also plan to utilize ideas from the Fisher Vector approach in \cite{csurka2011fisher} to combine both generative and discriminative models for the image classification task.

\item We anticipate experimenting with classic dimensionality reduction techniques such as PCA \cite{turk91} and LDA \cite{belhumeur97}. Provided the classifier is flexible enough, Spectral Hashing \cite{weiss2008} and Product Quantization \cite{jegou2011} appear to be promising recent approaches to dimensionality reduction.

\end{enumerate}

\bibliographystyle{plain}
\bibliography{proposal}

\end{document}